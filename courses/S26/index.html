<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
   "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en">

<head>
    <meta charset="UTF-8">
	<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-145389864-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-145389864-1');
</script>


    <link
          rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Alegreya Sans:ital,wght@0,100;0,300;0,400;0,500;0,600;0,700;1,100;1,300;1,400;1,500;1,600;1,700&amp;display=swap"
      data-tag="font"
    />
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&amp;display=swap"
      data-tag="font"
    />
	<title>
		Maryam Aliakbarpour
	</title>
	<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,400;0,700;1,400;1,700&family=Vollkorn&display=swap">
	<link rel="stylesheet" href="../../main.css" type="text/css"/>
</head>

<body>

<div class="nav">
	<div class="on"><a href="index.html">COMP 585 (Spring 26)</a></div> 
    <div class="off"><a href="index.html#description">Description</a></div>
	<div class="off"><a href="index.html#schedule">Schedule</a></div>
    <div class="off"><a href="index.html#UsefulMaterial">Useful material</a></div>
</div> 


<div id="empty"></div>






<div id="headpane">
	<div id="pagetitle">
	
		<div> 
			<p class="myname">COMP 585: <br> Probabilistic Toolkit for Learning and Computing</p>
			<p class="job">Instructor: <a href="https://maryamaliakbarpour.com">Maryam Aliakbarpour</a>
                <!-- <br> TA: <br> -->
            </p>
			<p class="contact">
				<b> Time:</b> Tuesdays and Thursdays 10:50 am - 12:05 pm <br>
				<b>Instructor's email:</b> maryama [at] rice [dot] edu<br>
                <b>Instructor's office hours: </b> by appointment<br>
                
				
                
				<br>
			</p>
			<button id="syllabusBTN" class="button">
            					<span>Syllabus</span>
         	 			</button>
					<script>
						document.getElementById("syllabusBTN").addEventListener("click", function() {
							window.open("Syllabus.pdf", "_blank");
						});
				</script>
		</div>

	</div>    
</div>








<div id="contentpane">
	<div id="content">
		
		<hr class="default">
		<!-- Description -->
		<div>
			<!-- Description title -->
			<div>
				<span class="anchor" id="description"></span>
				<h3>Description</h3>
            </div>
	
			<div> 
				<p>
				Randomness is one of the strongest tools which enables designing efficient algorithms. The applications of randomness in computer science spans machine learning algorithm, cryptography, networks, distributed systems. In this course, we study a variety of probabilistic tools and techniques that allow us to harness the power of randomness and apply it in algorithm design and learning theory. 
				</p>
			</div>

		</div>
        
        
        
        
        
        <hr class="default">
        <div>
            <!-- Schedule title -->
			<div>
				<span class="anchor" id="schedule"></span>
				<h3>Schedule</h3>
            </div>
            
            
			<table style="width:100%" frame=hsides rules=rows>
				<tr>
					<th>Date</th>
					<th>Material</th>
					<th>Assignment</th>
				</tr>
  				<tr>
				  	<td>01/13/2026	</td>	
                    <td> Probability overview<br> 
                        <a href = "Lecture01.pdf">Notes</a>, <a href="Lecture00.pdf">Logistics (slides)</a>
                    </td>
					<td>
                    Fill out the <a href="https://docs.google.com/spreadsheets/d/1i0jfBJtQkGWqCkCZmKga9_O9eqEoV9J_Y1atLM71XzA/edit?usp=sharing">scribe sign up sheet</a>.
                    <br>
                    Due on Tuesday, January 20, 11:59pm (CT) 
                    </td>
                    
                </tr>
  				
                <tr>
				  	<td>01/15/2026	</td>	
                    <td> Testing sortedness <br> 
                        <a href = "Lecture02.pdf">Notes</a></td>
					<td>
                    <!--
                    <a href= "pset1.pdf">Problem set 1</a>
                    <br>
                    Due on Tuesday, January 28, 11:59pm (CT) 
                    </td>
                    -->
                </tr>
                <tr>
				  	<td>01/20/2026	</td>
                    <td> Testing sortedness (General case) <br> 
                    <a href = "Lecture03.pdf">Notes</a>,
                        Reading: Section 4.3 in <a href="https://www.wisdom.weizmann.ac.il/~oded//pt-intro.html">IPT</a>
					<td>
                    </td>
                </tr>
                
                <tr>
				  	<td>01/22/2026	</td>
                    <td>Coin bias estimation and Concenteration of random variables<br> 
                    <a href = "Lecture04.pdf">Notes</a>
					<td>
                    </td>
                </tr>
                <tr>
				  	<td>01/28/2026	</td>
					<td>
                        Distribution testing: uniformity <br> 
                        <a href = "Lecture05.pdf">Notes</a>
                        <br> Reading: Section 11 in <a href="https://www.wisdom.weizmann.ac.il/~oded//pt-intro.html">IPT</a></td>
                </tr>
                <!--
                <tr>
				  	<td>01/30/2026	</td>
					<td>
                        Poissonization<br>
                        <a href = "Lecture05.pdf">Notes</a>
                        <br> Section 5.4 in <a href="https://a.co/d/al3HWNg">Probability and Computing book</a>
                        
                </tr>
                <tr>
				  	<td>02/04/2026	</td>
					<td>
                        Distribution testing: closeness testing <br>
                        <a href = "Lecture06.pdf">Notes</a>,
                    <td>
                    <a href= "pset2.pdf">Problem set 2</a>
                    <br>
                    Due on Tuesday, February 25, 11:59pm (CT) 
                    </td>
                </tr>
                <tr>
				  	<td>02/06/2026	</td>
					<td>
                        Distribution testing: Reducing L2-norm via flattening <br> 
                        <a href = "Lecture07.pdf">Notes</a> 
                    </td>
                </tr>
                
                <tr>
				  	<td>02/11/2026	</td>
					<td>
                        Gaussian distribution, CLT, Berry-Esseen Theorem<br> 
                        <a href = "Lecture08.pdf">Notes</a>
                    </td>
                </tr>
                <tr>
				  	<td>02/13/2026	</td>
					<td>
                        No class, spring recess.  
                        
                    </td>
                </tr>
                <tr>
				  	<td>02/18/2026	</td>
					<td>
                        Sub-Gaussian random variables<br> 
                        <a href = "Lecture09.pdf">Notes</a>, Reading: Section 2.5 in <a href="https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.pdf">HDP</a>
                    </td>
                    <td>
                    </td>
                </tr>
                <tr>
				  	<td>02/20/2026	</td>
					<td>
                        No class, class canceled.  
                        
                    </td>
                </tr>
                <tr>
				  	<td>02/25/2026	</td>
					<td>
                        Sub-Gaussian random variables (cont.)<br>
                        <a href = "Lecture10.pdf">Notes</a>, Reading: Section 2.5 in <a href="https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.pdf">HDP</a>
                    </td>
                    <td>
                    </td>
                </tr>
                <tr>
				  	<td>02/27/2026	</td>
					<td>
                        Sub-exponential random variables
                        <br> 
                        <a href = "Lecture11.pdf">Notes</a>, Reading: Section 2.7 in <a href="https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.pdf">HDP</a>
                    </td>
                    <td>
                    </td>
                </tr>
                
                <tr>
				  	<td>03/04/2026	</td>
					<td>
                        Sub-exponential random variables (cont.), Bernstein condition and inequality<br>
                        <a href="Lecture12.pdf">Notes</a>
                    </td>
                    <td>
                    <a href= "pset3.pdf">Problem set 3</a>
                    <br>
                    Due on Tuesday, March 25, 11:59pm (CT) 
                    <br>
                        <a href="project.pdf">Project guidelines</a> is posted.
                    </td>
                </tr>
                
                
                
                <tr>
				  	<td>03/06/2026	</td>
					<td>
                        Johnson-Lindenstrauss lemma<br>
                        <a href="Lecture13.pdf">Notes</a>, Reading: Section 5.3 in <a href="https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.pdf">HDP</a>
                    </td>
                    <td>
                    </td>
                </tr>
               
                <tr>
				  	<td>03/11/2026	</td>
					<td>
                        Linnear regression<br>
                        <a href="Lecture14.pdf">Notes</a>
                    </td>
                    <td>
                    </td>
                </tr>
                <tr>
				  	<td>03/13/2026	</td>
					<td>
                        PAC learning<br>
                        <a href="Lecture15.pdf">Notes</a>
                        <br>
                        Reading: <a href="https://www.cis.upenn.edu/~mkearns/teaching/COLT/KearnsVaziraniChapter1.pdf" >Chapter 1</a> of <a href="https://books.google.com/books?id=vCA01wY6iywC" target=_blank>ICLT</a>
                    </td>
                    <td>
                    </td>
                </tr>
                <tr>
				  	<td>03/18/2026	</td>
					<td> No class (Spring break)
                    </td>
                    <td> 
                    </td>
                </tr>
                <tr>
				  	<td>03/20/2026	</td>
					<td> No class (Spring break)
                    </td>
                    <td>
                    </td>
                </tr>
                
                
                <tr>
				  	<td>02/27/2026	</td>
					<td>
                        PAC learning<br>
                        <a href="Lecture13.pdf">Notes</a>, <a href="Lecture13_scribe.pdf">Scribe notes</a>, Reading: <a href="https://www.cis.upenn.edu/~mkearns/teaching/COLT/KearnsVaziraniChapter1.pdf" >Chapter 1</a> of <a href="https://books.google.com/books?id=vCA01wY6iywC" target=_blank>ICLT</a>
                    </td>
                    <td>
                    </td>
                </tr>
                
                
                <tr>
				  	<td>02/29/2026	</td>
					<td>
                        PAC learning, Uniform convergence<br>
                        <a href="Lecture14.pdf">Notes</a>, <a href="Lecture14_scribe.pdf">Scribe notes</a>, Reading: Section 4 of <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning">UML</a>
                    </td>
                    <td>
                    </td>
                </tr>
                
                
                <tr>
				  	<td>03/05/2026	</td>
					<td>
                        Uniform convergence (cont.), No free lunch theorem<br>
                        <a href="Lecture15.pdf">Notes</a>, <a href="Lecture15_scribe.pdf">Scribe notes</a>, Reading: Section 4 and 5 of <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning">UML</a>
                    </td>
                    <td>
                    </td>
                </tr>
                
                <tr>
				  	<td>03/07/2026	</td>
					<td>
                        VC dimension, Fundamental theorem of PAC learning, Sauer-Shelah-Perles lemma<br>
                        <a href="Lecture16.pdf">Notes</a>, <a href="Lecture16_scribe.pdf">Scribe notes</a>, Reading: Section 4 and 6 of <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning">UML</a>
                    </td>
                    <td>
                    </td>
                </tr>
                
                <tr>
				  	<td>03/12/2026	</td>
					<td> No class (Spring break)
                    </td>
                    <td>
                    </td>
                </tr>
                <tr>
				  	<td>03/14/2026	</td>
					<td> No class (Spring break)
                    </td>
                    <td>
                    <a href= "pset3.pdf">Problem set 3</a>
                    <br>
                    Due on Tuesday, April 2, 11:59pm (CT) 
                    </td>
                </tr>
                <tr>
				  	<td>03/19/2026	</td>
					<td>
                        Fundamental theorem of PAC learning (cont.)<br>
                        <a href="Lecture16.pdf">Notes (same file as the previous lecture)</a>, <br>
                        <a href="Lecture17_scribe.pdf">Scribe notes</a>, Reading: Section 4 and 6 of <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning">UML</a>
                    </td>
                    <td>
                    </td>
                </tr>
                <tr>
				  	<td>03/21/2026	</td>
					<td>
                        Fundamental theorem of PAC learning (cont.), Learning in the presence of noise<br>
                        <a href="Lecture18_scribe.pdf">Scribe notes</a>, Reading: Chapter 5 of <a href="https://books.google.com/books?id=vCA01wY6iywC" target=_blank>ICLT</a>
                    </td>
                    <td>
                    </td>
                </tr>
                
                <tr>
				  	<td>03/26/2026	</td>
					<td>
                        Learning boolean conjunctions, <br> Statistical query model<br>
                        <a href="Lecture19_scribe.pdf">Scribe notes</a>, Reading: Chapter 5 of <a href="https://books.google.com/books?id=vCA01wY6iywC" target=_blank>ICLT</a>
                    </td>
                    <td>
                    </td>
                </tr>
                
                <tr>
				  	<td>03/28/2026	</td>
					<td>
                        Learning in SQ model => learning in presence of noise<br>
                        <a href="Lecture20_scribe.pdf">Scribe notes</a>, Reading: Chapter 5 of <a href="https://books.google.com/books?id=vCA01wY6iywC" target=_blank>ICLT</a>
                    </td>
                    <td>
                    </td>
                </tr>
                
                <tr>
				  	<td>04/02/2026	</td>
					<td>
                        Weak learning => Strong learning<br>
                        <a href="Lecture21_scribe.pdf">Scribe notes</a>, Reading: Section 10 of <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning">UML</a>
                    </td>
                    <td>
                    </td>
                </tr>
                
                <tr>
				  	<td>04/04/2026	</td>
					<td>
                        Adaboost<br>
                        <a href="Lecture22_scribe.pdf">Scribe notes</a>, Reading: Section 10 of <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning">UML</a>
                    </td>
                    <td>
                    </td>
                </tr>                
                <tr>
				  	<td>04/09/2026	</td>
					<td>
                        Computational hardness of PAC learning: <br>
                        Learning 3-term DNFs
                        <br>
                        <a href="Lecture23_scribe.pdf">Scribe notes</a>, Reading: <a href="https://www.cis.upenn.edu/~mkearns/teaching/COLT/KearnsVaziraniChapter1.pdf" >Chapter 1.4</a> of <a href="https://books.google.com/books?id=vCA01wY6iywC" target=_blank>ICLT</a>
                    </td>
                    <td>
                    </td>
                </tr>                
                <tr>
				  	<td>04/11/2026	</td>
					<td>
                        Special topic: differential privacy 
                        <br>
                        <a href="Lecture24_scribe.pdf">Scribe notes</a>
                        <br> A good book: <a href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf" >The Algorithmic Foundations of Differential Privacy</a>
                    </td>
                    <td>
                    <a href= "pset4.pdf">Problem set 4</a>
                    <br>
                    Due on Friday, April 19, 11:59pm (CT) 
                    </td>
                </tr>
                               
                <tr>
				  	<td>04/16/2026	</td>
					<td>
                        Project presentations 
                    </td>
                    <td>
                    </td>
                </tr>
                
                               
                <tr>
				  	<td>04/18/2026	</td>
					<td>
                        Project presentations 
                    </td>
                    <td>
                    </td>
                </tr>
                -->
			</table>
            <br>
            <br>
		</div>
        
        
        
        
        
        
        <hr class="default">
		<!-- Description -->
		<div>
			<!-- Description title -->
			<div>
				<span class="anchor" id="UsefulMaterial"></span>
				<h3>Useful material</h3>
            </div>
	
            <ul line-height="3">
                <li margin-bottom="10px";>Some relevant textbooks (not required):
                    <ul>
                        <li> An Introduction to Computational Learning Theory, by Michael Kearns and Umesh Vazirani
                        </li>
                        
                        
                        <li><a href="https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.pdf">High-Dimensional Probability: An Introduction with Applications in Data Science</a>, by Roman Vershynin
                        </li>
                        
                        <li><a href="https://www.wisdom.weizmann.ac.il/~oded//pt-intro.html">Introduction to Property Testing</a>, by Oded Goldreich
                        </li>
                        
                        <li>Probability and Computing: Randomization and Probabilistic Techniques in Algorithms and Data Analysis, by Michael Mitzenmacher and Eli Upfal
                        </li>
                        
                        <li> <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning">Understanding Machine Learning: From Theory to Algorithms</a>, by Shai Shalev-Shwartz and Shai Ben-David
                        </li>

                    </ul>
                </li>
            
                <li><a href="https://www.lkozma.net/inequalities_cheat_sheet/ineq.pdf">Useful inequalities cheat sheet</a>, by L&aacute;szl&oacute; Kozma
                </li>
                
                <li><a href="https://www.overleaf.com/read/wfgznbpbnmfn#7665d7">LaTeX template</a> for scribe notes or problem set answers
                </li>
                
            </ul>
			<div> 
				<p>
                </p>
			</div>

		</div>
	</div>
</div>



	<div id="buffer"></div>
	
	<div id="footer">   
		<div>
    			<p>
    				Template by <a href="https://www.kiragoldner.com/blog/websites.html" target="_blank">Kira Goldner</a>&#169;, plus a little bit of love from Maryam Aliakbarpour.
    				<br> 
				Fonts and buttons are adapted from <a href="https://play.teleporthq.io/projects/remarkable-template-6-2lxogw" target="_blank">this free template</a> 
				by <a href="https://teleporthq.io/static-website-templates#templates-grid" target="_blank">Teleport HQ</a>
				<br> 
				&#169 2023 All Rights Reserved.
			</p>
		</div> 
	</div>
    <!-- If you really feel uncomfortable with giving me credit by name on your site, rather than deleting, please at lease uncomment and use the following logo credit. -->
    <!--div id="footer"><div id="logo"> <a href="https://www.kiragoldner.com/" target="_blank"><img src="https://www.kiragoldner.com/favicon.png" width="12pt"/></a></div><div>&#169; Template</div-->

  </body>


</html>
